<!DOCTYPE HTML>
<!--
	Hyperspace by HTML5 UP
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
<head>
		<title>Mukesh Barange</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>	
	<body>
		
		

		<!-- Sidebar -->
			<section id="sidebar">
				<div class="inner">
					<nav>
						<ul>
							<li><a href="#intro">Home</a></li>
							<li><a href="#resume">Resume</a></li>
							<li><a href="#research">Research</a></li>
							<li><a href="#supervison">Supervison</a></li>
							<li><a href="#projects">Projects</a></li>
							<li><a href="#teaching">Teaching</a></li>
							<li><a href="#publications">Publications</a></li>
							<li><a href="#contact">Contact</a></li>
						</ul>
					</nav>
				</div>
			</section>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Intro -->
					<section id="intro" class="wrapper style1 fullscreen fade-up">
						<div class="inner">
							<h1>Mukesh Barange</h1>
							<!--<p><strong>Post Doctorate</strong> at Institut national des sciences appliquées de Rouen Normandie (<a href="https://www.insa-rouen.fr/">INSA</a>)<br />
  						    -->
							I am currently working as a  postdoctoral researcher under the supervision of Mr. Alexandre Pauchet  and Mr. Julien Saunier  from June 2015 at INSA de Rouen,  France.  I have been awarded a Ph.D degree in computer science with class honors in March 2015 from the University of Western Brittany (Université de Bretagne Occidentale), Brest, France, advised by Professor Pierre Chevaillier.  I have worked as a temporary assistant lecturer and researcher  from Sept- 2013 to May- 2015 at ENIB, France.

							<br />
							<br />
								<p><strong>Member</strong> of the French Association for Virtual Reality (AFRV) 
							<br />	
								<strong>Member</strong> Associate Membership of Institute of Electronics and Telecommunication (AMIETE), India						
							<div>
						<div><strong>Personal Information</strong> </div>
						
						<div>
						<div style="text-align:left"><span style="font-size:13.3333px;font-weight:700"><br>
						</span></div>
						<table border="1" bordercolor="#888" cellspacing="0" style="text-align:left;border-collapse:collapse;border-color:rgb(136,136,136);border-width:1px">
							<tbody>
							<tr>
							<td style="width:282px;height:14px">&nbsp;Name<br>
							</td>
							<td style="width:474px;height:14px">&nbsp;Mukesh</td>
							</tr>
							<tr>
							<td style="width:282px;height:14px">&nbsp;Last name&nbsp;</td>
							<td style="width:474px;height:14px">&nbsp;BARANGE</td>
							</tr>
							<tr>
							<td style="width:282px;height:14px">&nbsp;Date of Birth</td>
							<td style="width:474px;height:14px">&nbsp;28/03/1983</td>
							</tr>
							<tr>
							<td style="width:282px;height:14px">&nbsp;Nationality</td>
							<td style="width:474px;height:14px">&nbsp;Indian</td>
							</tr>
							<tr>
							<td style="width:282px;height:14px">&nbsp;Marital status &nbsp; &nbsp;&nbsp;</td>
							<td style="width:474px;height:14px">&nbsp;Married</td>
							</tr>
							<tr>
							<td style="width:282px;height:14px">&nbsp;Professional status</td>
							<td style="width:282px;height:14px">&nbsp;Doctoral Researcher<br>
							</td>
							</tr>
							</tbody>
						</table>
						
						
						</div>
						
						
						
						
						
					</section>	
				<!-- Intro -->
					<section id="resume" class="wrapper style2 fade-up">
						<div class="inner">
							<h2>Resume</h2>
						<div class="features">
								<section>
									<span <li><a href="fichierpdf/RQ_Thesis.pdf" class="icon major fa-graduation-cap"></a></li></span>			
									<h3><a href="images/RQ_Thesis.html">PhD Thesis</a></h3>
									<p>Task-Oriented Communicative Capabilities of Agents in  Collaborative Virtual Environments for Training.</p>
									<p><i> Des agents avec des capacités communicatives orientées tâche dans les Environnements de réalité Virtuelle Collaboratifs pour l’Apprentissage.</i></p>
								
								
								
								</section>
								<section>
									<span class="icon major fa-university"></span>
									<h3>Research Domain</h3>
									<p>Human-Computer Interaction, Embodied Conversational Agents, Multimodal Interaction, Natural Language Processing, Dialogue Management, Autonomous Agent, Cooperation, Decision-Making, Knowledge Representation, Machine Learning.

</p>
									<!--p>Virtual Reality, Embodied Conversational Agent, Virtual Environment for Learning, Augmented Reality, .</p-->
								</section>
								
								<!--section>
								<span <li><a href="https://github.com/querrec" class="icon major fa-magic"></a></li></span>
									<h3>Developper</h3>
									<p>Main developer of MASCARET plateform. Get it on <a href="https://github.com/querrec">GitHub</a></p>
								</section-->
								<!-- <section>
									<span class="icon major fa fa-usb"></span>
									<h3>Teaching</h3>
									<p>Object programming ; Android ; Augmented Reality.</p>
								</section-->
								<!--section->
									<span <li><a href="fichierpdf/RQ_CV.pdf" class="icon major fa fa-user"></a></li></span>									
									<h3>Curriculum Vitae</h3>
									<p>You can download my Curriculum Vitae <a href="images/RQ_CV.pdf">here</a>.</p>
								</section> -->
							</div>
							<div>	<section>
									<span <li><a href="fichierpdf/RQ_CV.pdf" class="icon major fa fa-user"></a></li></span>									
									<h3>Curriculum Vitae</h3>
									<p>You can download my Curriculum Vitae <a href="images/RQ_CV.pdf">here</a>.</p>
								</section> 
								</div>
						</div>
						

					</section>

				<!-- One -->
					<section id="research" class="wrapper style4 spotlights">

								<section>
									<span ></span><a href="fichierpdf/Thesis.pdf" class="icon major fa-graduation-cap"></a></span>			
										My primary research interest is in the domain of collaborative virtual environments for training (CVET), and the natural language processing. Growing needs of educational and training requirements motivate the use of CVET that allows human users to work together with autonomous agents to perform a collective activity. The vision is inspired by the fact that the effective coordination improves productivity, and reduces the individual and team errors. The collective activity is not only a simple sum of individual actions; it requires team members to coordinate their activities with other team members and typically includes communicative actions. This requirement of the collaboration in human-agent teamwork has been the main topic of this research. 

										To act collectively in a CVET, participants have to communicate with each other and any combinations of real- and virtual- human interactions should be supported. Obviously, natural language communication, in many contexts, is the main channel of communication; nevertheless many evidences show the importance of multi-modal communication that includes facial expression, gestures and postures. In my current research, I address more specifically the natural language communication. Communication plays different roles in a collaborative context. Communicative actions may belong to the set of actions a participant is supposed to perform. The challenge is that how team members can generate the right utterance and how they can be able to interpret it. Likewise, communication can also be the only way for a participant to get information about its environment or the activity of others. The participant has to identify in which situation the communication can take place and to whom it will ask for the information. Communication is also needed to organize the collective activity. In this case, participants have to manage collectively the conversation and decide when and how to start the conversation.

										My research interest takes place in a general perspective to make the development of rich-content virtual reality applications more rational,  and I am interested in the following three points: (1) natural language communication between team members (both a user and virtual agents), (2) the decision-making by taking into account the actions of other partners, and (3) knowledge representation for collaborative activity, which enables agents to speak and act consistently towards the achievement of shared goals.

										The objective of the research is to provide human-like conversational behavior of the virtual agents in order to cooperate with a user and other agents to achieve shared goals. This coordination is based on the regulatory mechanisms of collective activity that passes through actions of communication between actors. In a collaborative virtual environment, to be able to coordinate the activity of one with the other, agents must share the common point of view of the common activity; they must be able to exchange information with others. So in this context, the agent must present both the deliberative behavior and conversational in order to be more rational. In the literature, these behaviors are treated independently. To integrate these behaviors, one of the difficulties is the representation of knowledge for decision-making and communication. Another issue is that how the agent can use the semantics of the virtual environment for decision-making and communication in natural language between participants. 

										The research goal  is to find out responses to the following questions: </br></br>

										<p>1.      How the natural language communication can be used to establish efficient coordination between team members in a mixed human-agent teamwork in CVET?</p>

										<p>2.      How the knowledge is organized and presented, which can be served for both the decision-making and conversational behaviors of the agent?</p>

										<p>3.      How the task-oriented multi-party conversation behavior of an agent can be modeled?</p>

										<p>4.      How to provide interleaving between deliberation and conversational behavior of the agent?</p>


								</section>


					</section>
						
						
						
						
						
						<section>
							<a href="#" class="image"><img src="images/research/Mascaret.png" alt="" data-position="center center" /></a>
							<div class="content">
								<div class="inner">
									<h2>Collaborative Conversational Agent Architecture</h2>
									
									<p>3.1	 </p>						
									
								</div>
							</div>
						</section>
						
						<section>
							<a href="#" class="image"><img src="images/research/ACA.png" alt="" data-position="25% 25%" /></a>
							<div class="content">
								<div class="inner">
									<h2>Narrative Interractive Embodied Conversational Agents</h2>
									<p>Our aim is to improve embodied conversational agents with tutor behavior by endowing 
									them with the capability to generate feedback in pedagogical interactions with learners. 
									The virtual agent feedback and the interpretation of the user’s feedback are based on the knowledge of the environment 
									(informed virtual environment defined using MASCARET), the interaction and the pedagogical strategies structured around classical intelligent 
									tutoring system models.</p>
									<ul class="actions">
										<!-- <li><a href="#" class="button">Learn more</a></li> -->
									</ul>
								</div>
							</div>
						</section>
				
						<section>
							<a href="#" class="image"><img src="images/research/Sc-Peda.png" alt="" data-position="top center" /></a>
							<div class="content">
								<div class="inner">
									<h2>Pedagogical Scenario</h2>
									<p>We defined a generic model for pedagogical scenarion for Virtual Environment for Learning.
									This model permits to create the configuration of the virtual environment where the exercice take place, the roles and the pedagogical activities.
									This model is base on MASCARET. The trainer create the environment by instanciting a domain model (defined with MASCARET).
									The pedagogical organisation is defined as a MASCARET organisation. The pedagogical scenarion is defined througth a UML 2 activities.
									All those concepts are also considered as a knowledge base for the agents.</p>

								</div>
							</div>
						</section>
						
						
						<section>
							<a href="#" class="image"><img src="images/research/Eval.png" alt="" data-position="center center" /></a>
							<div class="content">
								<div class="inner">
									<h2>Data Driven Methodologies for mixed humans-agents interaction</h2>
									<p> The main goal of this study is to assess the effectiveness of a virtual environment (VE) for learning complex procedures. 
									The first experiment we made is to validate the effectiveness of using a VE in the process of learning a new procedure (internal validity).
									The second one tested external validity of the VE, which is the participants’ ability to reproduce the acquired skills in a real context. 
									We find that internal and external validity must be evaluated before using a virtual environment in long-term procedure learning. 
									The results of such evaluations are a basis for future experiments aiming to optimize learning conditions in a VE and transferring the acquired skills
									in a real context</p>
									<ul class="actions">
										<!-- <li><a href="#" class="button">Learn more</a></li> -->
									</ul>
								</div>
							</div>
						</section>
						
	
						<section>
							<a href="#" class="image"><img src="images/research/Eval.png" alt="" data-position="center center" /></a>
							<div class="content">
								<div class="inner">
									<h2>Evaluation</h2>
									<p> The main goal of this study is to assess the effectiveness of a virtual environment (VE) for learning complex procedures. 
									The first experiment we made is to validate the effectiveness of using a VE in the process of learning a new procedure (internal validity).
									The second one tested external validity of the VE, which is the participants’ ability to reproduce the acquired skills in a real context. 
									We find that internal and external validity must be evaluated before using a virtual environment in long-term procedure learning. 
									The results of such evaluations are a basis for future experiments aiming to optimize learning conditions in a VE and transferring the acquired skills
									in a real context</p>
									<ul class="actions">
										<!-- <li><a href="#" class="button">Learn more</a></li> -->
									</ul>
								</div>
							</div>
						</section>
					</section>					
				<!-- Intro -->
				<!-- Intro -->
				<section id="supervison" class="wrapper style1 fade-up">
					<div class="inner">
						<div class="inner">
							<h2>Supervison</h2>
					<h2 class="borderize">PhD Thesis Guidance </h2> 
							
									<p class="supervison"><span class=" icon  fa-circle"> </span> <span>
									<a href="http://insa-rouen.fr"><strong>Usman Malik</Strong></a>: Towards Generic Multimodal Interaction Systems based on Machine Learning & Context Awareness (expected in 2020).</p>
									
									<p class="supervison"><span class=" icon  fa-circle"> </span> <span>
									<strong>Walid Rifi</Strong>: Emotional Agent Architecture for the mixed humans-agents Interaction.</p>
									
					<h2 class="borderize"> Master Thesis supervision </h2>
									
									<p class="supervison"><span class=" icon  fa-circle"> </span> <span>
									<strong>Luong Chi Tho.</Strong>: Gestion et Adaptation des comportements conversationnels et pédagogiques d’agents virtuels dans un Environnements de réalité Virtuelle Collaboratif de Formation (EVCF).</p>					

									<p class="supervison"><span class=" icon  fa-circle"> </span> <span>
									<strong>Walid Rifi</Strong>: Gestion et Adaptation des comportements conversationnels et pédagogiques d’agents virtuels dans un Environnements de réalité Virtuelle Collaboratif de Formation (EVCF).</p>					

						
					<h2 class="borderize"> Final Year Project supervision </h2>
									
									<p class="supervison"><span class=" icon  fa-circle"> </span> <span>
									<strong>Amaury Lacave</Strong>: Gestion et Adaptation des comportements conversationnels et pédagogiques d’agents virtuels dans un Environnements de réalité Virtuelle Collaboratif de Formation (EVCF).</p>					
	
									<p class="supervison"><span class=" icon  fa-circle"> </span> <span>
									<strong>Jierui Zha</Strong>: Gestion et Adaptation des comportements conversationnels et pédagogiques d’agents virtuels dans un Environnements de réalité Virtuelle Collaboratif de Formation (EVCF).</p>					
	
									<p class="supervison"><span class=" icon  fa-circle"> </span> <span>
									<strong>Antoine Robin</Strong>: Gestion et Adaptation des comportements conversationnels et pédagogiques d’agents virtuels dans un Environnements de réalité Virtuelle Collaboratif de Formation (EVCF).</p>					
	
									<p class="supervison"><span class=" icon  fa-circle"> </span> <span>
									<strong>Gabriel</Strong>: Gestion et Adaptation des comportements conversationnels et pédagogiques d’agents virtuels dans un Environnements de réalité Virtuelle Collaboratif de Formation (EVCF).</p>					
	
									<p class="supervison"><span class=" icon  fa-circle"> </span> <span>
									<strong>Cloé Decultot </Strong>: Gestion et Adaptation des comportements conversationnels et pédagogiques d’agents virtuels dans un Environnements de réalité Virtuelle Collaboratif de Formation (EVCF).</p>					
	
										<p class="supervison"><span class=" icon  fa-circle"> </span> <span>
									<strong>Killian Jaubert</Strong>: Gestion et Adaptation des comportements conversationnels et pédagogiques d’agents virtuels dans un Environnements de réalité Virtuelle Collaboratif de Formation (EVCF).</p>					

									<p class="supervison"><span class=" icon  fa-circle"> </span> <span>
									<strong>Anatole Chaumont</Strong>: Gestion et Adaptation des comportements conversationnels et pédagogiques d’agents virtuels dans un Environnements de réalité Virtuelle Collaboratif de Formation (EVCF).</p>					


					<h2 class="borderize"> 4th Year Project supervision </h2>
			
									<p class="supervison"><span class=" icon  fa-circle"> </span> <span>
									<strong>Amaury Lacave</Strong>: Gestion et Adaptation des comportements conversationnels et pédagogiques d’agents virtuels dans un Environnements de réalité Virtuelle Collaboratif de Formation (EVCF).</p>					
	
			
									<p class="supervison"><span class=" icon  fa-circle"> </span> <span>
									<strong>Oksana Allaire</Strong>: Gestion et Adaptation des comportements conversationnels et pédagogiques d’agents virtuels dans un Environnements de réalité Virtuelle Collaboratif de Formation (EVCF).</p>					
	
			
									<p class="supervison"><span class=" icon  fa-circle"> </span> <span>
									<strong>Pierre Larrenie</Strong>: Gestion et Adaptation des comportements conversationnels et pédagogiques d’agents virtuels dans un Environnements de réalité Virtuelle Collaboratif de Formation (EVCF).</p>					
	
			
									<p class="supervison"><span class=" icon  fa-circle"> </span> <span>
									<strong>Quentin Loiseau</Strong>: Gestion et Adaptation des comportements conversationnels et pédagogiques d’agents virtuels dans un Environnements de réalité Virtuelle Collaboratif de Formation (EVCF).</p>					
	
			
									<p class="supervison"><span class=" icon  fa-circle"> </span> <span>
									<strong>Timothe Bernard</Strong>: Gestion et Adaptation des comportements conversationnels et pédagogiques d’agents virtuels dans un Environnements de réalité Virtuelle Collaboratif de Formation (EVCF).</p>					
	
	
									
					</div>
				</section>				
			<!-- Intro -->
					<section id="projects" class="wrapper style2 spotlights">
						<div class="inner">
							<h2>Projects</h2></div>
							
						<section>
							<a href="#" class="image"><img src="images/projects/EVALEVAH.png" alt="" data-position="center center" /></a>
							<div class="content">
								<div class="inner">
									<h2>DAISI (DAta scIence : méthodologieS et applIcations)</h2>
									<p>The goal of the DAISI project is to semi-automatically construct dialogue models from human interaction corpora using data sciences methodological tools,
									 and particularly sequence and pattern analysis methods developed within DAISI.
									  Modeling multimodal and affective dialogical interactions is a well known problem in human-machine interaction and whose applications are numerous
									   and multidisciplinary: computer science, psychology, human and social sciences, biology and health, etc. Although the tools used differ by domain,
									    this modeling most often exploits a corpus of annotated multimodal dialogues, the analysis of which aims to identify a set of significant
									     recurring behaviors. In the proposed use case, the corpus of dialogues consists of raw information from audio or video signals
									      and our goal is to transform this data into an interaction model.
									       We therefore envisage to tackle this problem by searching for regularities in the audio and video sequences.
									        In other words, it consists in showing, from a set of sequences, patterns or subsequences that are recurrent in dialogues. 
									        From a methodological point of view, we plan to exploit dictionariy-based machine learning algorithm, with the aim of identifying the 
									        recurring patterns as the dictionary items that will be most frequently used during the dialogues. 
									        The learned dialogue model developed can be exploited in different ways according to the application domain. 
									        For example, if the model is intended for a virtual emotional character, it should integrate multimodal and emotional 
									        components used both to recognize the user's dialogic intentions and to manage the linguistic and nonverbal behavior of the virtual character (2017-Present).</p>
 										 <div style="text-align:left;font-size:23px">
										<table border="1" bordercolor="#888" cellspacing="0" style="border-collapse:collapse;border-color:rgb(136,136,136);border-width:1px">
										<tbody>
										<tr>
										<td style="width: 631px; height: 230px;">&nbsp;Thematics:
										<font size="2"><span style="font-size:13.3333px">Health / Multi modality / </span>Logistics performance<span style="font-size:13.3333px">&nbsp;/ Wind turbine</span></font>

										<div style="font-size:13.3333px"><font size="3">Laboratories :&nbsp;</font> <font size="2">LITIS&nbsp;</font></div>
										<div><font size="3">financier(s)</font><font size="3" style="font-size:13.3333px">&nbsp;: </font><font size="2">European Union, Normandy Region</font></div>
										<div style="font-size:13.3333px"><font size="3">Funding(s) : </font> <font size="2">FEDER,&nbsp;</font><span style="font-size:small">Normandy Region</span><font size="2">, ANR</font></div>
										<div><font size="3">Coordinator</font><font size="3" style="font-size:13.3333px">&nbsp;:</font> <font size="2">University of Rouen Normandy</font></div>
										<div><font size="3">Partners</font><font size="3" style="font-size:13.3333px">:</font> <font size="2">University of Rouen Normandy</font><font size="2" style="font-size:13.3333px">&nbsp;(LITIS, LMRS, CETAPS), INSERM INSA Rouen Normandy (LITIS) CEREMA</font></div>
										</td>
										</tr>
										</tbody>
										</table>
										</div>
 									<ul class="actions">
									</ul>
								</div>
							</div>
						</section>

						<section>
							<a href="#" class="image"><img src="images/projects/VirtualLab.png" alt="" data-position="25% 25%" /></a>
							<div class="content">
								<div class="inner">
									<h2>NARECA (NARrative Embodied Conversational Agent)</h2>
									<p>One of the real challenges for research in artificial intelligence is to enable humans to interact with the machine, 
									without having to make specific changes in the application and using all the means necessary for optimal communication.
									 The need to adapt the machine to human behavior becomes more challenging when the user is a child, with cognitive and communicative abilities still developing.
									  Designing such an interface requires to improve existing models of dialogue, as well as their use in an Embodied Conversational Agent (en: ECA, fr: ACA).
									   However, it is currently not possible to design a generic ECA without taking into account several scientific limits
									    (speech processing, prosody, emotion, nonverbal behavior, vocabulary size, linguistic development, etc.) .

The objective of the NARECA project is to optimize the modeling of dialogue interactions and use these models in an ECA. 
The scientific experiments envisaged are linked to extraction of multi-modal and affective interaction models on real dialogues (both methodology and tools).
 Our approach wants to identify recurring patterns of behavior in dialogues, annotate them automatically using NLP tools and then apply extraction patterns and
  data mining techniques on these annotations.
   The product of this study will be a software platform for analysis of dialogues, as well as demonstrative application integrating
    the dialogue patterns collected: an Affective Narrative ECA. The expected benefits are multidisciplinary and the evaluation of our approach will be through this application (2016-2017). </p>
									<ul class="actions">
									</ul>
								</div>
							</div>
						</section>						
						

						<section>
							<a href="#" class="image"><img src="images/projects/east.png" alt="" data-position="center center" /></a>
							<div class="content">
								<div class="inner">									
									<h2><a href="http://projet-east.blogspot.fr/">EAST</a></h2>
									<p>It is an e-education project of the national program of future investments. 
									The objectif of this project is to develop 3D interactive environments for the learning of concepts, technical gestures and procedures in the field of renewable energies. 
									Some partners: the Cesi, Insa de Rouen, Afpa, Dassault Systèmes, etc. (2015-2016).</p> 
									<ul class="actions">
									</ul>
								</div>
							</div>
						</section>



						<section>
							<a href="#" class="image"><img src="images/projects/east.png" alt="" data-position="25% 25%" /></a>
							<div class="content">
								<div class="inner">									
									<h2><a href="http://projet-east.blogspot.fr/">CORVETTE (COllaboRative Virtual Environment for Technical Training and Experiment)</a></h2>
									<p>
 CORVETTE  project is collaborative project, funded by the ANR, aims to facilitate collaboration between a real human and virtual humans when performing complex tasks (requiring multiple actors) in a virtual environment (VE). 
 The project focuses on natural language communication between the real and virtual human users in task-oriented collaborative situations, the autonomy of the virtual human, and natural and real-time interaction with the VE. 
 The goal is to design a collaborative virtual environment for technical training (learning procedures, maintenance, fault simulation...), in which virtual entities can be the avatar of users collaborating to complete a task (2010-2014).
.</p> 
									<ul class="actions">
									</ul>
								</div>
							</div>
						</section>

						<section>
							
							<a href="#" class="image"><img src="images/projects/gaspar.png" alt="" data-position="top center" /></a>
							<div class="content">
								<div class="inner">
									<h2>IMMERSIVITE</h2>
									<p>The  market for educational applications inspired by video games is booming, for education, vocational training, or training to manage extreme situations. These "serious games" are all the more effective they are graphically realistic. But when the player has to interact with virtual characters, exchanges lack spontaneity, as predefined and stereotyped.

 The immersivé collaborative project was born from this observation and expertise of its partners. Each in its field, has developed highly specialized skills in terms of interactivity: real-time dialogue, analysis of facial expressions, facial animation, virtual learning environment. 
 Immersivé way for all game designers need to insert NPC (non-player) in an interactive scene. 
 In particular, serious games are more effective when these characters are expressive and animated realistically.
  The goal of the project is to  offer a solution to communicate with virtual characters in a natural, spontaneous way (2011-2013).

</p>
									<ul class="actions">
									</ul>
								</div>
							</div>
						</section>
						

						<section>
							<a href="#" class="image"><img src="images/projects/Cultural.png" alt="" data-position="center center" /></a>
							<div class="content">
								<div class="inner">
									<h2>Thesis Experimental Scenario : Montage du Meuble</h2>
									<p>This project is a collaboration with <a href="http://www.cfv.univ-nantes.fr/">Centre François Viète</a> to apply MASCARET to cultural heritage.</p>
									<ul class="actions">
									</ul>
								</div>
							</div>
						</section>
												
						
						
						<section>
							<a href="#" class="image"><img src="images/projects/Cultural.png" alt="" data-position="center center" /></a>
							<div class="content">
								<div class="inner">
									<h2>Cultural Heritage : BrestCoz</h2>
									<p>This project is a collaboration with <a href="http://www.cfv.univ-nantes.fr/">Centre François Viète</a> to apply MASCARET to cultural heritage (2010).</p>
									<ul class="actions">
									</ul>
								</div>
							</div>
						</section>
						
						
						

						<!--
						<section>
							<a href="#" class="image"><img src="images/Mascaret.png" alt="" data-position="top center" /></a>
							<div class="content">
								<div class="inner">
									<h2>Im-Data</h2>
									<p>Je suis mis à disposition pour 20% de mon temps à l'IRT B-COM dans le projet Im-Data. J'y apporte le modèle Mascaret que je développe et je l'intègre aux plateformes de réalité augmenté pour la maintenance (2013-2015).</p>
									<p>I am spending 20% of my time at <a href="https://b-com.com/fr">IRT B-com</a>. I'm integrating MASCARET to an augmented reality platforms for maintenance (2013-2015).</p>
									<ul class="actions">
									</ul>
								</div>
							</div>
						</section>-->				


						<!-- <section>
							<a href="#" class="image"><img src="images/projects/Mascaret.png" alt="" data-position="center center" /></a>
							<div class="content">
								<div class="inner">
									<h2>Immersivite</h2>
									<p>Ce projet Pôle Images et Réseaux auquel je participe a pour objectif la réalisation d'une API de conception d'environnements virtuels pour les serious games. Mascaret est utilisé pour la conception de l'environnement virtuel (2010-2013).</p>
									<ul class="actions">
									</ul>
								</div>
							</div>
						</section> -->

									
					</section>			
					
					
					
							
				<!-- Intro -->	
				<!-- Two -->
				
				
					<section id="teaching" class="wrapper style4 fade-up">
						<div class="inner">
							<h2>Teaching</h2>
								<section>
								<p class="teaching"><span class="icon big fa fa-university" style="font-size:30px"> </span> <span>
											<span><strong>INSA de Rouen (<a href="http://www.enib.fr/">INSA</a>)</strong><br />
											<br /></span>				
									
								</section>
								
								<section>
									<p class="teaching"><span class=" icon min fa fa-android"> </span> <span>
											<span><strong>Android</strong><br />
											<br /></span>
								</section>
								<section>
									<p class="teaching"><span class=" icon min fa fa-file-code-o"> </span> <span>
											<span><strong>Object Oriented Programming</strong><br />
											<br /></span>
								</section>
								<section>
								
									<p class="teaching"><span class=" icon min fa-desktop"> </span> <span>
											<span><strong>Augmented Reality</strong><br />
											<br /></span>
								</section>
												
								<section>
								<p class="teaching"><span class="icon big fa fa-university" style="font-size:30px"> </span> <span>
											<span><strong> ENIB (<a href="http://aul.edu.lb/">ENIB</a>)</strong><br />
											<br /></span>
								<!-- <!--	<span class="icon fa-university"></span> -->
									<!-- <h3>Arts Sciences and Technology University in Lebanon (<a href="http://aul.edu.lb/">AUL</a>)</h3> -->
									<!-- <p>Phasellus convallis elit id ullam corper amet et pulvinar. Duis aliquam turpis mauris, sed ultricies erat dapibus.</p> -->
								</section>
								
																					
								<section>
								<p class="teaching"><span class=" icon min fa fa-file-code-o"> </span> <span>
											<span><strong>Introduction to Virtual Reality</strong><br />
											<br /></span>
								</section>
								
								<section>
								<p class="teaching"><span class="icon big fa fa-university" style="font-size:30px"> </span> <span>
											<span><strong> VIT (<a href="http://aul.edu.lb/">VIT</a>)</strong><br />
											<br /></span>
								<!-- <!--	<span class="icon fa-university"></span> -->
									<!-- <h3>Arts Sciences and Technology University in Lebanon (<a href="http://aul.edu.lb/">AUL</a>)</h3> -->
									<!-- <p>Phasellus convallis elit id ullam corper amet et pulvinar. Duis aliquam turpis mauris, sed ultricies erat dapibus.</p> -->
								</section>
								
																					
								<section>
								<p class="teaching"><span class=" icon min fa fa-file-code-o"> </span> <span>
											<span><strong>Introduction to Virtual Reality</strong><br />
											<br /></span>
								</section>							

							</div>
							
					</section>
					
					<!-- Three -->
					<section id="publications" class="wrapper style1 fade-up">
						<div class="inner">
							<h2>Publications</h2>
							
							<div class="row_publication" style="text-align : left;">
		
									<h2 class="borderize">International Journals</h2> 
									
											<p class="publication"><span class=" icon  fa-arrow-circle-right"> </span> 
											
											Julien Saunier, <strong>Mukesh Barange</strong>, Bernard Blandin, Ronan Querrec (2016). <i>A methodology for the design of pedagogically adaptable learning environments.
											The International Journal of Virtual Reality, 2016, 16 (01): 15-21 <a href="http://www.ijvr.org/web/uploads/pdf/16(16-01)9x2.pdf" target="_blank">[.pdf]</a>.</p>
									
											<p class="publication"><span class=" icon  fa-arrow-circle-right"> </span> <span>
											<strong>Mukesh Barange</strong>, Alexandre Kabil, Camille De Keukelaere, Pierre Chavaillier (2014).&nbsp <i>Collaborative Behaviour Modelling of Virtual Agents using Communication in a Mixed&nbsp;Human-Agent Teamwork.&nbsp;</i>
											International Journal on Advances in Intelligent Systems, 7(3–4): 423–438.&nbsp;<a href="https://docs.google.com/file/d/0B5tt9Hp5YJescTFTNFp3MDVQaTg/edit">[.pdf]</a>.</p>
											
											
											<p class="publication"><span class=" icon  fa-arrow-circle-right"> </span> <span>
											Thomas Lopez, Pierre Chevaillier, Valérie Gouranton, Paul Evrard, Florian Nouviale, <strong>Mukesh Barange</strong>, Rozenn Bouville-Berthelot, Bruno Arnaldi (2014).
											<i>Collaborative Virtual&nbsp;Training with Physical and Communicative Autonomous Agents.&nbsp;</i> 
											Journal of Visualization&nbsp;and Computer Animation, 25(3–4): 487–495 <a href="http://onlinelibrary.wiley.com/doi/10.1002/cav.1583/full" target="_blank">[.pdf]</a>.</p>
							
								  <h2 class="borderize">International Conferences</h2>
											
											<p class="publication"><span class=" icon  fa-arrow-circle-right"> </span> <span>
											Ovidiu Serban, <strong>Mukesh Barange</strong>, Sahba Zojaji, Alexandre Pauchet, Adeline Richard, and Émilie Chanoni. 2017. <i>Interactive Narration with a Child:&nbsp;
											Impact of Prosody and Facial Expressions.</i> In Proceedings of 19th ACM International&nbsp;</i>
											Conference on Multimodal Interaction (ICMI’17). November 13–17, 2017, Glasgow, United Kingdom (Rank B).&nbsp;. </p>
											
											<p class="publication"><span class=" icon  fa-arrow-circle-right"> </span> <span>
											<strong>Mukesh Barange</strong>, Julien Saunier, and Alexandre Pauchet. 2017.&nbsp;<i>Multiparty Interactions for Coordination in a Mixed Human-Agent Teamwork.</i>
											In the 17th International Conference on Intelligent Virtual Agents (IVA2017),&nbsp; Aug 27-30, Stockholm (Rank B).</p>
											
											<p class="publication"><span class=" icon  fa-arrow-circle-right"> </span> <span>
											Alexandre Pauchet, Ovidiu Serban Mélodie Ruinet, Adeline Richard, Emilie Chanoni and <strong>Mukesh Barange</strong> 2017.&nbsp;<i>
											Interactive Narration with a Child: Avatar <i>versus</i> Video-displayed Human.</i> 
											In the 17th International Conference on Intelligent Virtual Agents (IVA2017),&nbsp; Aug 27-30, Stockholm (Poster) (Rank B)</p>

											<p class="publication"><span class=" icon  fa-arrow-circle-right"> </span> <span>
											<strong>Mukesh Barange</strong>, Julien Saunier, and Alexandre Pauchet. 2017.
											<i>Pedagogical Agents as Team Members: Impact of Proactive and Pedagogical Behavior on the User. In&nbsp;</i>
											Proceedings of the 16th Conference on Autonomous Agents and MultiAgent Systems &nbsp;(AAMAS '17). 
											International Foundation for Autonomous Agents and Multiagent Systems, Richland, SC, 791-800, &nbsp;(</font>Rank A*)</font>.</p>
											
											<p class="publication"><span class=" icon  fa-arrow-circle-right"> </span> <span>
											Julien Saunier, <strong>Mukesh Barange</strong>, Bernard Blandin, Ronan Querrec, Joanna Taoum (2016),
											<i>Designing Adaptable Virtual Reality Learning Environments</i>,
											19th Virtual Reality International Conference VRIC’16 Laval Virtual, March 23-25, Laval, France&nbsp;.</p>
											
											<p class="publication"><span class=" icon  fa-arrow-circle-right"> </span> <span>
											<strong>Mukesh Barange</strong>, Alexandre Kabil, Camille De Keukelaere, Pierre Chavaillier (2014).&nbsp;
											<i>Communicative Capabilities of Agents for the Collaboration in a Human-Agent Team,</i>&nbsp;
											Proceeding of the 7th International Conference on Advances in Computer-Human Interactions,&nbsp;pages 389–394, Barcelona, Spain&nbsp;</span><span style="font-size:10pt">(best paper award)</span><a href="https://drive.google.com/file/d/0B5tt9Hp5YJesZDFPb0RLbHBrdWM/view?usp=sharing">[.pdf]</a></p>
											
											<p class="publication"><span class=" icon  fa-arrow-circle-right"> </span> <span>
											<strong>Mukesh Barange</strong>, Alexandre Kabil, Camille De Keukelaere, Pierre Chavaillier (2014).&nbsp;
											<i>Task-Oriented Conversational Behavior of Agents for Collaboration in Human-Agent Teamwork,&nbsp;</i>
											12th Int. Conf. on Practical Applications of Agents and Multi-Agent Systems,</i>&nbsp;pages&nbsp;25–37, Salamanca, Spain.&nbsp;<a href="http://link.springer.com/chapter/10.1007%2F978-3-319-07551-8_3#page-1">[.pdf]</a>.</p>
											
											<p class="publication"><span class=" icon  fa-arrow-circle-right"> </span> <span>
											<strong>Mukesh Barange</strong>, Pierre De Loor, Vincent Louis, Ronan Querrec, Julien Soler, Thanh-Hai Trinh, Éric Maisel and Pierre Chevaillier (2011).&nbsp;
											<i>Get Involved in an Interactive Virtual&nbsp;Tour of Brest Harbour: Follow the Guide and Participate,&nbsp;</i>
											Proceedings of the International&nbsp;Conference "Intelligent Virtual Agents" (IVA’11), Lecture Notes in Computer Science,&nbsp;pages 93-99, Reykjavik, Iceland.<a href="https://drive.google.com/file/d/0B5tt9Hp5YJesbHJxNS1nS1VfeUU/view?usp=sharing">[.pdf]</a>.</p>
											
											<p class="publication"><span class=" icon  fa-arrow-circle-right"> </span> <span>
											Pierre Chevaillier, Than-Hai Trinh, <strong>Mukesh Barange</strong>, Pierre De Loor, Frédéric Devilllers,&nbsp;Julien Soler, Ronan Querrec (2011).&nbsp;
											<i>Semantic Modelling of Virtual Environments Using&nbsp;MASCARET,&nbsp;</i>
											Proceedings of the Fourth Workshop on Software &nbsp;engineering and Architectures&nbsp;for Realtime Interactive Systems, SEARIS’11 (In conjunction with IEEE Virtual&nbsp;Reality 2011)</i>, pages 93–99, Singapore.<a href="https://drive.google.com/file/d/0B5tt9Hp5YJesVDhaTHdQNGxIRG8/view?usp=sharing">[.pdf]</a>.</p>
											
											<p class="publication"><span class=" icon  fa-arrow-circle-right"> </span> <span>
											T.-H. Trinh, P. Chevaillier,&nbsp;<strong>M. Barange</strong>, J. Soler, P. De Loor, and R. Querrec (2011).&nbsp;
											<i>Integrating semantic directional relationships into virtual environments: A meta-modelling&nbsp;approach In JVRC 2011:&nbsp;</i>
											Proceedings of the Joint Virtual Reality &nbsp;conference of EGVE –&nbsp;EuroVR</i>, pages 67–74, 20-21 September, Nottingham, UK.<a href="https://drive.google.com/file/d/0B5tt9Hp5YJesMHBhSEkzWUNvbTg/view?usp=sharing">[.pdf]</a>.</p>



								   <h2 class="borderize">Demo Papers</h2> 
								
											<p class="publication"><span class=" icon  fa-arrow-circle-right"> </span> <span>
											<strong>Mukesh Barange</strong>, Julien Saunier, Alexandre Pauchet (2016). 
											<i>Une architecture d'agent conversationnel collaboratif et pédagogique pour les simulations immersives multi-agents et multi-utilisateurs</i>, JFSMA-2016, Rouen France.</p>
				
										
											<p class="publication"><span class=" icon  fa-arrow-circle-right"> </span> <span>
											<strong>Mukesh Barange</strong>, Alexandre Kabil, Pierre Chavaillier, (2014). <i>The C2-BDI Agent Architecture for Teamwork Coordination Using Spoken Dialogues between Virtual Agents and Users</i>,
											 Proceedings of the 12th International Conference on Practical Applications of Agents and Multi-Agent Systems, pages 315–318, Salamanca, Spain. [.pdf]</p>


									<h2 class="borderize">Publications without scientific committee</h2> 

											<p class="publication"><span class=" icon  fa-arrow-circle-right"> </span> <span>
											 Usman Malik, <strong>Mukesh Barange</strong>, Julien Saunier and Alexandre Pauchet (2018),
											 <i> Towards Generic Multimodal Interaction Systems based on machine learning and context awareness</i>,
											  Workshop Affect, Compagnon Artificiel, Interaction (WACAI 2018), l’ile de Porquerolles, France. (accepted)</p>
											
											<p class="publication"><span class=" icon  fa-arrow-circle-right"> </span> <span>
											Ovidiu Serban, <strong>Mukesh Barange</strong>, Sahba Zojaji, Alexandre Pauchet, Adeline Richard and Emilie Chanoni  (2018). 
											<i>Impact of Prosody and Facial Expressions on Interactive Narration with a Child. </i>
											Workshop Affect, Compagnon Artificiel, Interaction (WACAI 2018), l’ile de Porquerolles, France. (accepted)</p>
											
											<p class="publication"><span class=" icon  fa-arrow-circle-right"> </span> <span>
											<strong>Mukesh Barange</strong>, Alexandre Pauchet, Julien Saunier (2016). 
											<i>Agents pédagogiques interactifs pour l’apprentissage d’une tâche procédurale. </i>
											Workshop Affect, Compagnon Artificiel, Interaction (WACAI 2016), Brest, France.</p>
											
											<p class="publication"><span class=" icon  fa-arrow-circle-right"> </span> <span>
											<strong>Mukesh Barange</strong>, Rozenn Bouville Berthelot, Pierre Chevaillier, Camille De Keukelaere, Valérie Gouranton, Alexandre Kabil, Thomas Lopez, Florian Nouviale, Bruno Arnaldi (2013).
											<i> Échange de Connaissances entre Utilisateurs et Agents Autonomes dans les EVFC. </i>
											Journées de l’Association Française de Réalité Virtuelle (AFRV), pages 1–8, Laval, France. [.pdf]</p>
											
											<p class="publication"><span class=" icon  fa-arrow-circle-right"> </span> <span>
											<strong>Mukesh Barange</strong>, Pierre Chevaillier (2012).
											<i>Model-based approach for natural language  generation from semantic virtual environment.</i> 
											 Workshop Affect, Compagnon Artificiel, Interaction (WACAI), pages 111–118, Grenoble, France.[.pdf]</p>

							</div>
						</div>
					</section>

				<!-- Four -->
					<section id="contact" class="wrapper style2 fade-up">
						<div class="inner" style="text-align : left;">
						<h2>Contact</h2>
						<div class="inner" style="text-align : left;">
					 		<div class="split style1">
								<!--section>
									<form method="post" action="#">
										<div class="field half first">
											<label for="name">Name</label>
											<input type="text" name="name" id="name" />
										</div>
										<div class="field half">
											<label for="email">Email</label>
											<input type="text" name="email" id="email" />
										</div>
										<div class="field">
											<label for="message">Message</label>
											<textarea name="message" id="message" rows="5"></textarea>
										</div>
										<ul class="actions">
											<li><a href="" class="button submit">Send Message</a></li>
										</ul>
									</form>
								</section--> 
								<section>
								
									<ul class="contact" style="text-align : left;">
											<li>
											<p class="contact"><span class=" icon alt fa-home" style="font-size:26px"> </span> 
												<span><a href="https://www.google.com/maps/place/INSA+Rouen+Normandy/@49.3849792,1.066137,17z/data=!3m1!4b1!4m5!3m4!1s0x47e0ddf2136ef7b9:0x7f83ca5859b93b67!8m2!3d49.3849757!4d1.0683257"><strong>Address</strong></a><br />    
												Mukesh Barange,<br />
												INSA de Rouen<br />
												Avenue de l’Université - BP 8<br />
												76801 Saint-Étienne-du-Rouvray Cedex<br />
												France<br />
										</span>  
								</section>
								<section>
									
										<p class="contact"><span class=" icon  alt fa-envelope" style="font-size:26px"> </span> 
											<span><strong>Email</Strong><br /></span> 
											<a href="#">mukesh.barange_at_insa-rouen.fr</a>
																	
										<p class="contact"> <span class=" icon  min alt fa-phone" style="font-size:26px"></span>
											<span><strong>Phone</Strong><br /></span> 
											<span>+33 2 32 95 25 15</span> 								
											 
										</li>
										<ul class="icons">
												<!--li><a href="https://github.com/querrec" class="icon major fa-github"><span class="label">GitHub</span></a></li-->
												<li><a href="https://scholar.google.com/citations?user=AlhMTOoAAAAJ&hl=en" class="icon major featured fa-book"><span class="label">Google Scholar</span></a></li>
												<li><a href="https://www.linkedin.com/in/mukesh-barange-617094b/" class="icon major fa-linkedin"><span class="label">LinkedIn</span></a></li>
											</ul> 								
											 
										</li>
								
									</ul>
								</section>
							</div>							
						</div>
					</section>

			</div>

		<!-- Footer -->
			<footer id="footer" class="wrapper style2-alt">
				<div class="inner">
					<ul class="menu">
					 <li>&copy; Mukesh Barange.</li><li>Design: Html5 Up</li>
					</ul>
				</div>
			</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>
			
			<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
			

	</body>

</html>
